{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded hard_debias\n",
      "successfully loaded double_hard_debias\n",
      "successfully loaded utils\n",
      "Original vocab size:  322636\n",
      "Restricted vocab size:  47974\n",
      "Neutral vocab size:  47597\n",
      "successfully loaded data_embeddings\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import zipfile\n",
    "import utils\n",
    "import hard_debias as hd\n",
    "import double_hard_debias as dhd\n",
    "import data_embeddings as data # this takes a while, files are retrieved from Wang et al.'s Github repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiasing GloVe embeddings\n",
    "Following the concepts described in the paper by [Wang et al. (2020)](https://arxiv.org/abs/2005.00965), we set out to replicate the proposed Double-Hard Debias algorithm. As the code uploaded to the [github repository by the original authors](https://github.com/uvavision/Double-Hard-Debias) is partly not understandable, partly (in our eyes) slightly deviating from what is proposed in the paper and partly simply not executable (without the respective files from which not all are uploaded) we present here a new, full implementation of the algorithm as described in Wang et al. (2020)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Debias\n",
    "The authors make use of the Hard Debias algorithm proposed by [Bolukbasi et al. (2016)](https://arxiv.org/pdf/1607.06520.pdf) and we sticked to the original paper in order to re-implement Hard Debias. The paper describes two steps: First, the gender subspace has to be identified. As a second step Hard Debias neutralizes and equalizes the word embeddings.\n",
    "### Step 1: Identify gender subspace\n",
    "Inputs: word sets $W$, defining sets $D_1, D_2, ..., D_n \\subset W$ as well as embedding $\\{\\vec{w}\\in\\mathbb{R}^d\\}_{w\\in W}$ and integer parameter $k \\geq 1$.   \n",
    "Let $$\\mu_i := \\sum_{w\\in D_i}\\vec{w}/|D_i|$$ be the means of the defining sets. Let the bias subspace $B$ be the first $k$ rows of SVD($C$) where $$C:=\\sum_{i=1}^n \\sum_{w\\in D_i}(\\vec{w}-\\mu_i)^T(\\vec{w}-\\mu_i)/|D_i|$$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_subspace = hd.idtfy_gender_subspace(data.embedding, data.vocab, data.w2id, data.definitional_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Hard de-biasing (neutralize and equalize)\n",
    "Hard Debias then neutralizes the word embeddings by transforming each $\\vec{w}$ such that every word $w\\in N$ has zero projection in the gender subspace. For each word $w\\in N$, we re-embed $\\vec{w}$: $$\\vec{w}:=\\vec{w}-\\vec{w}_B$$\n",
    "Please see `hard_debias.py` for the full implementation of Hard Debias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double-Hard Debias\n",
    "We sticked strictly to the pseudocode from Wang et al. (2020):   \n",
    "![](dhd_pseudocode.png \"Double-Hard Debias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 female most biased words:  ['actress', 'pregnant', 'louise', 'therese', 'abbess', 'sister', 'chairwoman', 'alumna', 'princess', 'ballerina']\n",
      "first 10 male most biased words:  ['john', 'himself', 'his', 'brother', 'led', 'son', 'colonel', 'successor', 'nephew', 'footballing']\n"
     ]
    }
   ],
   "source": [
    "# first, the male and female biased word sets need to be obtained:\n",
    "index_f, index_m = dhd.most_biased(data.embedding, gender_subspace)\n",
    "\n",
    "female_most_biased = [data.vocab[i] for i in index_f]\n",
    "male_most_biased = [data.vocab[i] for i in index_m]\n",
    "print(\"first 10 female most biased words: \", female_most_biased[:10])\n",
    "print(\"first 10 male most biased words: \", male_most_biased[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to `double_hard_debias.py` for the full implementation. From the paper alone we could not infer whether Wang et al. (2020) used the `equalize_pairs`, the original set by Bolukbasi et al. (2016), for the equalizing step in Hard Debias or the `female_male_pairs` as both were uploaded to the github repository. So we implemented both (the words contained in both sets are similar, but `female_male_pairs` contains more words). As we observed no difference in the results using either word set, we decided to continue with the `equalize_pairs` to stick to the original Bolukbasi et al. (2016) paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest PC:  3\n"
     ]
    }
   ],
   "source": [
    "# result using equalize_pairs for equalizing\n",
    "debiased_1 = dhd.double_hard_debias(data.embedding, data.w2id, data.embedding_neutral, data.id_neutral, data.equalize_pairs, index_m, index_f, gender_subspace)\n",
    "\n",
    "with zipfile.ZipFile('debiased.zip', 'w', compression=zipfile.ZIP_DEFLATED) as folder:\n",
    "    file_1 = open('debiased.p', 'wb')\n",
    "    pickle.dump(debiased_1, file_1)\n",
    "    file_1.close()\n",
    "    folder.write('debiased.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallest PC:  3\n"
     ]
    }
   ],
   "source": [
    "# result using female_male_pairs for equalizing\n",
    "debiased_2 = dhd.double_hard_debias(data.embedding, data.w2id, data.embedding_neutral, data.id_neutral, data.female_male_pairs, index_m, index_f, gender_subspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The resulting embeddings are identical: True\n"
     ]
    }
   ],
   "source": [
    "print(\"The resulting embeddings are identical:\", (debiased_1 == debiased_2).all())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
