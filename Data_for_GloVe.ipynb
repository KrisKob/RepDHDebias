{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url of dataset, can be replaced\n",
    "url_dataset = \"http://mattmahoney.net/dc/text8.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 31344016 / 31344016"
     ]
    }
   ],
   "source": [
    "wget.download(url_dataset)\n",
    "\n",
    "with zipfile.ZipFile('text8.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('text8.zip', 'r') as zip_ref:\n",
    "    # only take limited number of characters, loose 'b prefix\n",
    "    txt = (zip_ref.read('text8')[:500000].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = txt.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_words(data, number_words, stride):\n",
    "    \"\"\"splits given data into multiple bag of words\n",
    "    \n",
    "    takes\n",
    "    data = original word list\n",
    "    number_words = number of words used in the sequence\n",
    "    stride\n",
    "    \n",
    "    returns\n",
    "    bags = list conftaining bag of words\"\"\"\n",
    "    \n",
    "    # number of possible \"convolutions\"\n",
    "    count = round((len(data)-number_words)/stride)\n",
    "    \n",
    "    bags = []\n",
    "    j = 0\n",
    "    for i in range(count):\n",
    "        bags.append(list(data[j:(j+sequence_length)]))\n",
    "        j = j+stride\n",
    "        \n",
    "    return bags\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_frequency(data, chosen_word):\n",
    "    \"\"\"\n",
    "    takes\n",
    "    data = list of sentences\n",
    "    chosen_word = word that should be increased in frequency\n",
    "    \n",
    "    returns\n",
    "    data_freq = altered dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    data_freq = data.copy()\n",
    "    for sentence in data:\n",
    "        if chosen_word in sentence:\n",
    "            data_freq.append(sentence)\n",
    "            \n",
    "    return data_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of consecutive words:  83150\n",
      "first three sentences:\n",
      "First: ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english', 'revolution', 'and', 'the', 'sans', 'culottes', 'of', 'the', 'french', 'revolution', 'whilst']\n",
      "Second: ['the', 'term', 'is', 'still', 'used', 'in', 'a', 'pejorative', 'way', 'to', 'describe', 'any', 'act', 'that', 'used', 'violent', 'means', 'to', 'destroy', 'the', 'organization', 'of', 'society', 'it', 'has', 'also', 'been', 'taken', 'up', 'as']\n",
      "Third: ['a', 'positive', 'label', 'by', 'self', 'defined', 'anarchists', 'the', 'word', 'anarchism', 'is', 'derived', 'from', 'the', 'greek', 'without', 'archons', 'ruler', 'chief', 'king', 'anarchism', 'as', 'a', 'political', 'philosophy', 'is', 'the', 'belief', 'that', 'rulers']\n",
      "last sentence, should contain chosen word boy : True\n"
     ]
    }
   ],
   "source": [
    "# set hyperparameters for bag of words\n",
    "sequence_length = 30\n",
    "stride = 30\n",
    "chosen_word = \"boy\"\n",
    "\n",
    "print(\"number of consecutive words: \", len(txt))\n",
    "\n",
    "data = create_bag_of_words(txt, sequence_length, stride)\n",
    "print(\"first three sentences:\\nFirst: {0}\\nSecond: {1}\\nThird: {2}\".format(data[0], data[1], data[2]))\n",
    "#print(x, data)\n",
    "#print(\"boy\" in txt)\n",
    "\n",
    "fake_data = fake_frequency(data, chosen_word)\n",
    "\n",
    "print(\"last sentence, should contain chosen word\", chosen_word, \":\", (chosen_word in fake_data[-1]))\n",
    "print(fake_data[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
